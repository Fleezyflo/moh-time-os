#!/usr/bin/env python3
"""
Documentation Inventory for MOH TIME OS.
Task: SYSPREP 0.4 — Docs Inventory
"""

import json
import os
import re
from datetime import datetime
from pathlib import Path

REPO_ROOT = Path(__file__).parent.parent
DATA_DIR = REPO_ROOT / "data"

# Active operations files (these are always ACTIVE-OPERATIONS)
OPERATIONS_FILES = {
    "HEARTBEAT.md",
    "IDENTITY.md",
    "GUARDRAILS.md",
    "DIRECTIVE.md",
    "BRIEF_SYSTEM_PREP.md",
    "TASK_PROTOCOL.md",
    "AGENTS.md",
    "SOUL.md",
    "USER.md",
    "TOOLS.md",
    "CHANGELOG.md",
}

# Patterns that indicate historical specs
HISTORICAL_PATTERNS = [
    r'v[0-3]\.', r'_v[0-3]_', r'V[0-3]\.', r'_V[0-3]_',
    r'DEPRECATED', r'deprecated', r'LEGACY', r'legacy',
    r'OLD', r'old_', r'_old', r'archive',
    r'draft', r'DRAFT', r'wip', r'WIP',
]

# Patterns that indicate agent output
AGENT_OUTPUT_PATTERNS = [
    r'agent_output', r'agent-output',
    r'session_', r'run_log', r'RUN_LOG',
    r'\d{4}-\d{2}-\d{2}.*output',
    r'evidence/', r'logs/',
]

# Patterns that indicate active specs
ACTIVE_SPEC_PATTERNS = [
    r'SPEC.*v2\.9', r'v29', r'_v29',
    r'ui_spec_v21', r'UI-SPEC-v2\.9',
    r'CLIENT-UI-SPEC',
]


def get_file_metadata(file_path: Path) -> dict:
    """Get file metadata."""
    try:
        stat = file_path.stat()
        return {
            "path": str(file_path.relative_to(REPO_ROOT)),
            "size": stat.st_size,
            "mtime": datetime.fromtimestamp(stat.st_mtime).isoformat(),
            "lines": len(file_path.read_text(errors="ignore").splitlines())
        }
    except Exception as e:
        return {
            "path": str(file_path),
            "size": 0,
            "mtime": "",
            "lines": 0,
            "error": str(e)
        }


def get_first_lines(file_path: Path, n: int = 30) -> str:
    """Get first N lines of a file."""
    try:
        content = file_path.read_text(errors="ignore")
        lines = content.split("\n")[:n]
        return "\n".join(lines)
    except Exception:
        return ""


def classify_file(file_path: Path, first_lines: str) -> str:
    """Classify a markdown file into categories."""
    path_str = str(file_path)
    filename = file_path.name

    # Check for operations files
    if filename in OPERATIONS_FILES:
        return "ACTIVE-OPERATIONS"

    # Check if in tasks directory
    if "/tasks/" in path_str or "\\tasks\\" in path_str:
        return "ACTIVE-OPERATIONS"

    # README/DOCS
    if filename.lower() in ["readme.md", "contributing.md", "license.md", "deploy.md", "architecture.md"]:
        return "README/DOCS"

    # Check path for patterns
    for pattern in AGENT_OUTPUT_PATTERNS:
        if re.search(pattern, path_str, re.IGNORECASE):
            return "AGENT-OUTPUT"

    for pattern in HISTORICAL_PATTERNS:
        if re.search(pattern, path_str, re.IGNORECASE):
            return "HISTORICAL-SPEC"
        if re.search(pattern, filename, re.IGNORECASE):
            return "HISTORICAL-SPEC"

    # Check content for patterns
    content_lower = first_lines.lower()

    # Check for active spec indicators
    for pattern in ACTIVE_SPEC_PATTERNS:
        if re.search(pattern, path_str, re.IGNORECASE) or re.search(pattern, first_lines, re.IGNORECASE):
            return "ACTIVE-SPEC"

    # Check for historical indicators in content
    if any(x in content_lower for x in ["deprecated", "legacy", "this file is outdated", "superseded by"]):
        return "HISTORICAL-SPEC"

    # Check for spec indicators
    if any(x in content_lower for x in ["specification", "spec:", "## overview", "## endpoints", "## schema"]):
        # Determine if historical or active based on path/content
        if any(x in path_str.lower() for x in ["v1", "v2", "v3", "old", "legacy"]) and "v29" not in path_str.lower():
            return "HISTORICAL-SPEC"
        return "ACTIVE-SPEC"

    # Check for agent/run patterns in content
    if any(x in content_lower for x in ["run log", "session", "agent output", "generated by"]):
        return "AGENT-OUTPUT"

    # Default to UNKNOWN if can't classify
    return "UNKNOWN"


def identify_canonical_specs(files: list) -> dict:
    """Identify the canonical specification files."""
    canonical = {
        "API Spec": None,
        "Schema Spec": None,
        "UI Spec": None,
        "Architecture": None,
    }

    for f in files:
        if f["category"] != "ACTIVE-SPEC":
            continue

        path_lower = f["path"].lower()
        name_lower = Path(f["path"]).name.lower()

        # API Spec
        if ("api" in path_lower or "spec_router" in path_lower) and "spec" in name_lower:
            if canonical["API Spec"] is None or "v2.9" in f["path"] or "v29" in f["path"]:
                canonical["API Spec"] = f

        # Schema Spec
        if "schema" in name_lower or "schema" in path_lower:
            if canonical["Schema Spec"] is None:
                canonical["Schema Spec"] = f

        # UI Spec
        if "ui" in path_lower and "spec" in name_lower:
            if canonical["UI Spec"] is None or "v2.9" in f["path"] or "v29" in f["path"]:
                canonical["UI Spec"] = f

        # Architecture
        if "architecture" in name_lower or "architecture" in path_lower:
            if canonical["Architecture"] is None:
                canonical["Architecture"] = f

    return canonical


def generate_report(files: list, canonical: dict) -> str:
    """Generate markdown report."""
    date_str = datetime.now().strftime("%Y-%m-%d")

    # Count by category
    counts = {}
    for f in files:
        cat = f["category"]
        counts[cat] = counts.get(cat, 0) + 1

    lines = [
        f"# Documentation Inventory — {date_str}",
        "",
        "## Summary",
        f"- Total .md files: {len(files)}",
        f"- ACTIVE-SPEC: {counts.get('ACTIVE-SPEC', 0)}",
        f"- ACTIVE-OPERATIONS: {counts.get('ACTIVE-OPERATIONS', 0)}",
        f"- HISTORICAL-SPEC: {counts.get('HISTORICAL-SPEC', 0)}",
        f"- AGENT-OUTPUT: {counts.get('AGENT-OUTPUT', 0)}",
        f"- README/DOCS: {counts.get('README/DOCS', 0)}",
        f"- UNKNOWN: {counts.get('UNKNOWN', 0)}",
        "",
        "---",
        "",
        "## Canonical Specs (current governing documents)",
        "| Purpose | File | Last Modified |",
        "|---------|------|---------------|",
    ]

    for purpose, f in canonical.items():
        if f:
            lines.append(f"| {purpose} | `{f['path']}` | {f['mtime'][:10]} |")
        else:
            lines.append(f"| {purpose} | _(not identified)_ | — |")

    # ACTIVE-SPEC files
    lines.extend([
        "",
        "---",
        "",
        "## ACTIVE-SPEC Files (keep in tree)",
        "| Path | Lines | Last Modified |",
        "|------|-------|---------------|",
    ])

    for f in sorted([f for f in files if f["category"] == "ACTIVE-SPEC"], key=lambda x: x["path"]):
        lines.append(f"| `{f['path']}` | {f['lines']} | {f['mtime'][:10]} |")

    # ACTIVE-OPERATIONS files
    lines.extend([
        "",
        "---",
        "",
        "## ACTIVE-OPERATIONS Files (keep in tree)",
        "| Path | Lines | Last Modified |",
        "|------|-------|---------------|",
    ])

    for f in sorted([f for f in files if f["category"] == "ACTIVE-OPERATIONS"], key=lambda x: x["path"]):
        lines.append(f"| `{f['path']}` | {f['lines']} | {f['mtime'][:10]} |")

    # README/DOCS files
    lines.extend([
        "",
        "---",
        "",
        "## README/DOCS Files (keep in tree)",
        "| Path | Lines | Last Modified |",
        "|------|-------|---------------|",
    ])

    for f in sorted([f for f in files if f["category"] == "README/DOCS"], key=lambda x: x["path"]):
        lines.append(f"| `{f['path']}` | {f['lines']} | {f['mtime'][:10]} |")

    # HISTORICAL-SPEC files
    lines.extend([
        "",
        "---",
        "",
        "## HISTORICAL-SPEC Files (archive candidates)",
        "| Path | Lines | Last Modified |",
        "|------|-------|---------------|",
    ])

    for f in sorted([f for f in files if f["category"] == "HISTORICAL-SPEC"], key=lambda x: x["path"]):
        lines.append(f"| `{f['path']}` | {f['lines']} | {f['mtime'][:10]} |")

    # AGENT-OUTPUT files
    lines.extend([
        "",
        "---",
        "",
        "## AGENT-OUTPUT Files (archive candidates)",
        "| Path | Lines | Last Modified |",
        "|------|-------|---------------|",
    ])

    for f in sorted([f for f in files if f["category"] == "AGENT-OUTPUT"], key=lambda x: x["path"]):
        lines.append(f"| `{f['path']}` | {f['lines']} | {f['mtime'][:10]} |")

    # UNKNOWN files
    lines.extend([
        "",
        "---",
        "",
        "## UNKNOWN (needs manual review)",
        "| Path | Lines | First line |",
        "|------|-------|------------|",
    ])

    for f in sorted([f for f in files if f["category"] == "UNKNOWN"], key=lambda x: x["path"]):
        first = f.get("first_line", "")[:50].replace("|", "\\|")
        lines.append(f"| `{f['path']}` | {f['lines']} | {first} |")

    return "\n".join(lines)


def main():
    print("Starting Documentation Inventory...")

    # Find all .md files
    print("Scanning for .md files...")
    md_files = list(REPO_ROOT.rglob("*.md"))
    md_files = [f for f in md_files if ".venv" not in str(f) and "node_modules" not in str(f)]
    print(f"Found {len(md_files)} .md files")

    # Process each file
    print("Classifying files...")
    files = []
    for i, file_path in enumerate(md_files):
        if i % 100 == 0 and i > 0:
            print(f"  Processed {i}/{len(md_files)}...")

        metadata = get_file_metadata(file_path)
        first_lines = get_first_lines(file_path)
        category = classify_file(file_path, first_lines)

        files.append({
            **metadata,
            "category": category,
            "first_line": first_lines.split("\n")[0] if first_lines else ""
        })

    # Identify canonical specs
    print("Identifying canonical specs...")
    canonical = identify_canonical_specs(files)

    # Generate report
    print("Generating report...")
    report = generate_report(files, canonical)

    # Save
    date_str = datetime.now().strftime("%Y%m%d")
    output_file = DATA_DIR / f"docs_inventory_{date_str}.md"
    output_file.write_text(report)

    print(f"\n✓ Report saved to: {output_file}")

    # Summary
    counts = {}
    for f in files:
        cat = f["category"]
        counts[cat] = counts.get(cat, 0) + 1

    print("\n=== DOCS INVENTORY SUMMARY ===")
    print(f"Total files:        {len(files)}")
    print(f"ACTIVE-SPEC:        {counts.get('ACTIVE-SPEC', 0)}")
    print(f"ACTIVE-OPERATIONS:  {counts.get('ACTIVE-OPERATIONS', 0)}")
    print(f"HISTORICAL-SPEC:    {counts.get('HISTORICAL-SPEC', 0)}")
    print(f"AGENT-OUTPUT:       {counts.get('AGENT-OUTPUT', 0)}")
    print(f"README/DOCS:        {counts.get('README/DOCS', 0)}")
    print(f"UNKNOWN:            {counts.get('UNKNOWN', 0)}")

    archive_candidates = counts.get('HISTORICAL-SPEC', 0) + counts.get('AGENT-OUTPUT', 0)
    print(f"\nArchive candidates: {archive_candidates}")


if __name__ == "__main__":
    main()
